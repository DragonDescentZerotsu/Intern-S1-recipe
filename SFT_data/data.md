
## 1. Source and Coverage
Our data is based on **Therapeutics Data Commons (TDC)**, which provides 60+ AI-ready datasets across 20+ task types in drug discovery, such as ADMET/toxicity, molecular property prediction, drug–target interaction, generation, and others. TDC ships these tasks with standard train/valid/test splits and well-defined evaluation setups, so we reuse their splits instead of inventing our own. 

In this milestone we are **not limited to a single toxicity task (e.g. hERG)**; the project can draw from multiple TDC benchmark groups (e.g. ADMET group, property prediction tasks) as long as they can be rendered into a language-model-friendly format. This matches what recent therapeutics LLMs (Tx-LLM / TxGemma family) do: they pool many TDC tasks and unify them by prompting. 

## 2. LM-Style Conversion (TxGemma template)
All original TDC entries (which may come as SMILES tables, CSVs, or sequence-level data) were **converted into text prompts using the same style as TxGemma/Tx-LLM**: a short instruction, optional domain background, the actual query (often containing a SMILES string or another therapeutic representation), and a slot for the model to answer. This makes every example look like a normal chat / instruction-tuning sample, so we can fine-tune Intern-S1 without writing a task-specific collator. The example below is exactly such a converted sample. 

Each JSON line therefore has:
- `input`: chat-style prompt, already including `<|im_start|>user`, task description, TDC context text, and the molecule/protein string.
- `output`: what the assistant should say, typically a short chain-of-thought block plus the final label (e.g. `(A)` / `(B)`).

This format mirrors my current directory:
- `/data2/tianang/projects/Intern-S1/SFT_data/SFT_data/GPT_TDC_CLS/training.jsonl`
- `/data2/tianang/projects/Intern-S1/SFT_data/SFT_data/GPT_TDC_CLS/dev.jsonl`
- `/data2/tianang/projects/Intern-S1/SFT_data/SFT_data/GPT_TDC_CLS/test.jsonl`

## 3. Splits
We keep the **7 : 1 : 2** split that TDC uses or recommends:
- **training** (`training.jsonl`) – ~70%
- **development** (`validation.jsonl`) – ~10%
- **test** (`test.jsonl`) – ~20%

TDC’s own goal is to give “train/validation/test” per dataset, so keeping the same split lets us later compare to TDC-style leaderboards. Different TDC tasks we include will each preserve their own splits. 

## 4. Current Modality Status
At this milestone **all samples are text-only / SMILES-only after template conversion.** We have **not** yet attached 3D structural information to these rows, because the finetuning / packing pipeline for Intern-S1 is still being set up and we want to validate the SFT path first.

Concretely:
- current input = TDC row → TxGemma-style prompt
- current output = label / answer the model should produce
- current loss = `answer_only_loss` on the assistant turn

This gives us a clean baseline to check that Intern-S1 can be trained on therapeutics-style instructions.

## 5. Planned 3D Extension
Once we finalize the “we will go 3D” route, we will **augment the same TDC molecules with 3D conformers generated by RDKit** (e.g. ETKDG to generate coordinates, then optional MMFF/UFF optimization). RDKit can do this directly from the SMILES strings that are already present in the TDC samples, so we don’t have to change the dataset identity — we just add another view of each molecule. The 3D payload can then be:
1. stored alongside the JSONL (e.g. separate `.npy`/`.sdf` per ID) and referenced in the text, or
2. serialized into a token-like form for the 3D branch of the model, depending on which fusion strategy we implement (projector vs. interleaved tokens, inspired by Chem3DLLM / Orthus). 

So the timeline is:
1. **Milestone 1 (now):** text-only, TDC→TxGemma promptified, 7/1/2 split.
2. **After pipeline is stable:** regenerate the same IDs with RDKit 3D and plug them into the multimodal path.

## 6. Example
```json
{
  "input": "<|im_start|>user\nInstructions: Answer the following question about drug properties.\nContext: ... (TDC task background here) ...\nQuestion: Given a drug SMILES string, predict whether it (A) ... (B) ...\nDrug SMILES: <SMILES>...</SMILES>\nAnswer:<|im_end|>\n<|im_start|>assistant",
  "output": "\n<think>\n\n</think>\n(A)<|im_end|>\n"
}
